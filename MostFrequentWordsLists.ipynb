{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T19:52:48.865230Z",
     "start_time": "2019-09-25T19:50:45.206519Z"
    }
   },
   "outputs": [],
   "source": [
    "from python_files.getwrdlist import *\n",
    "from python_files.load_corpus import *\n",
    "from IPython.display import clear_output\n",
    "import pyperclip\n",
    "\n",
    "word_dict_p = {}\n",
    "for item in word_dict:\n",
    "    for i in range(0,len(word_dict[item])):\n",
    "        word_dict_p[item + str(i+1).replace(\"1\",\"\")] = word_dict[item][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T19:58:48.022782Z",
     "start_time": "2019-09-25T19:57:00.663017Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded corpus from corpus/hjk.summary (88.316596M words)\n",
      "Loaded corpus from corpus/wikipedia.summary (61.987162M words)\n",
      "Loaded corpus from corpus/opensub.summary (196.755303M words)\n",
      "Created combined corpus\n"
     ]
    }
   ],
   "source": [
    "##Load combined frequency data\n",
    "\n",
    "hjk_corpus  = load_corpus_summary(\"corpus/hjk.summary\", inverse_dict)[\"corpus\"]\n",
    "wiki_corpus = load_corpus_summary(\"corpus/wikipedia.summary\", inverse_dict)[\"corpus\"]\n",
    "open_corpus = load_corpus_summary(\"corpus/opensub.summary\", inverse_dict)[\"corpus\"]\n",
    "\n",
    "freq_ = create_combined_corpus([hjk_corpus, wiki_corpus, open_corpus])\n",
    "\n",
    "for word in word_dict:\n",
    "    if word not in freq_:\n",
    "        freq_[word] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1>Verbs</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T22:22:38.587223Z",
     "start_time": "2019-07-19T22:22:38.580777Z"
    }
   },
   "source": [
    "The following lines of code create a file called \"verbs.html\" that contains the most common verbs.\n",
    "\n",
    "Verbs in Croatian can be grouped in families. Like phrasal verbs in English, Croatian verbs can be formed combining a base form with a preposition; the only difference is that in Croatian the preposition goes in front of the verb and they form a single word (they are not separated by a space). Verbs that have the same base belong to the same \"extended family\", as I decided to call them. The file verbs_extended.txt contains the all the families of verbs\n",
    "\n",
    "On the other hand, Croatian verbs can be perfective or imperfective, and one can often list perfective/imperfective pairs. I have called this pairs \"cousins\". Cousins are listed in verbs_cousins.txt\n",
    "\n",
    "The complete family of a verb is the extended family plus all the cousins of each of the members of the family.\n",
    "\n",
    "To make the listing easier, I've created a filed called \"verbs_main_list.txt\" that contains the list of the main verbs of each family. This list was built by hand considering the most common verbs. Also, I've tried to list mostly the imperfective verbs.\n",
    "\n",
    "The FREQ_THRESHOLD determines where the frequency threshold is set to display other family members of each verb of the main verbs list. If the frequency of a member of the family is lower than the threshold, in is not added to the final list. I determined 0.014 to be a good number considering a intermidiate level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T18:45:20.814016Z",
     "start_time": "2019-07-29T18:45:20.810028Z"
    }
   },
   "outputs": [],
   "source": [
    "FREQ_THRESHOLD = 0.014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T18:45:20.842949Z",
     "start_time": "2019-07-29T18:45:20.815015Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## Load extended families and cousins\n",
    "##\n",
    "cousins_  = {}\n",
    "extended_ = {}\n",
    "fulllist_ = []\n",
    "\n",
    "with open(\"verbs_lists/verbs_cousins.txt\",\"r\",encoding=\"UTF-8\") as f:\n",
    "    for line in f:\n",
    "        line_ = line.replace(\"\\n\",\"\").split(\",\")\n",
    "        cousins_[line_[0]] = line_[1]\n",
    "    f.close()\n",
    "\n",
    "antisymmetric_words = {}\n",
    "for item in cousins_:\n",
    "    if not cousins_[item] in cousins_:\n",
    "        antisymmetric_words[cousins_[item]] = item\n",
    "        \n",
    "cousins_.update(antisymmetric_words)\n",
    "    \n",
    "with open(\"verbs_lists/verbs_extended.txt\",\"r\",encoding=\"UTF-8\") as f:\n",
    "    for line in f:\n",
    "        line_ = line.replace(\"\\n\",\"\").split(\",\")\n",
    "\n",
    "        stem = line_[0]\n",
    "        line_.remove(stem)\n",
    "        extended_[stem] = line_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T18:45:21.064385Z",
     "start_time": "2019-07-29T18:45:20.845931Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## Load main verbs list,\n",
    "###\n",
    "main_verb_list = []     ## LIST WITH THE MAIN STEMS\n",
    "extended_verb_list = [] ## LIST WITH MAIN STEMS PLUS EXTENDED FAMILY PLUS COUSINS\n",
    "\n",
    "with open(\"verbs_lists/verbs_main_list.txt\",\"r\",encoding=\"UTF-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.replace(\"\\n\",\"\")\n",
    "        \n",
    "        main_verb_list.append(line)\n",
    "        \n",
    "        if line not in extended_:\n",
    "            extended_[line] = [line]\n",
    "        \n",
    "        extended_verb_list.extend(extended_[line])\n",
    "        \n",
    "        if line not in extended_verb_list:\n",
    "            extended_verb_list.append(line)\n",
    "            \n",
    "        if line in cousins_ and cousins_[line] not in extended_verb_list:\n",
    "            extended_verb_list.append(cousins_[line])      \n",
    "            \n",
    "        for item in extended_[line]:\n",
    "            if item in cousins_ and cousins_[item] not in extended_verb_list:\n",
    "                extended_verb_list.append(cousins_[item])\n",
    "\n",
    "        \n",
    "    f.close()\n",
    "\n",
    "### Sort list\n",
    "### Create a dictionary with general frequency scores for word families\n",
    "### Each verb on the main list gets a score equal to the highest frequency\n",
    "### of all the verbs of the family (extended and cousins)\n",
    "main_verb_list_score_dict = {}\n",
    "for item in main_verb_list:\n",
    "    \n",
    "    max_score = 0\n",
    "    if item in freq_:\n",
    "        max_score = freq_[item]\n",
    "    if item in cousins_ and cousins_[item] in freq_ and freq_[cousins_[item]] > max_score:\n",
    "        max_score = freq_[cousins_[item]]\n",
    "    \n",
    "    for subitem in extended_[item]:\n",
    "        if subitem in freq_ and freq_[subitem] > max_score:\n",
    "            max_score = freq_[subitem]\n",
    "        if subitem in cousins_ and cousins_[subitem] in freq_ and freq_[cousins_[subitem]] > max_score:\n",
    "            max_score = freq_[cousins_[subitem]]\n",
    "            \n",
    "    main_verb_list_score_dict[item] = max_score\n",
    "    \n",
    "main_verb_list.sort(key = lambda x:main_verb_list_score_dict[x], reverse=True)\n",
    "\n",
    "## Find verbs that are on the list, and verb in the list that are below the freq threshold\n",
    "exclude = []\n",
    "for word in main_verb_list:\n",
    "    if word not in word_dict:\n",
    "        continue\n",
    "    if freq_[word.replace(\"2\",\"\")] < FREQ_THRESHOLD:\n",
    "        exclude.append(word)\n",
    "for word in exclude:\n",
    "    main_verb_list.remove(word)\n",
    "    \n",
    "## Missing verbs\n",
    "for word in word_dict:\n",
    "    for w in word_dict[word]:\n",
    "        if \"Verb\" not in w.typ:\n",
    "            continue\n",
    "        if w.name in main_verb_list:\n",
    "            continue\n",
    "        if freq_[w.name] < FREQ_THRESHOLD:\n",
    "            continue\n",
    "        main_verb_list.append(word)\n",
    "        \n",
    "\n",
    "    \n",
    "## Find family members that lie below the frequency threshold \n",
    "uncommon_verbs = []\n",
    "for word in extended_verb_list:\n",
    "    word = word.replace(\"2\",\"\")\n",
    "    if word not in freq_:\n",
    "        freq_[word] = 0\n",
    "    if freq_[word] < FREQ_THRESHOLD:\n",
    "        #print(word + \" (\" + str(freq_[word]) + \")\")\n",
    "        uncommon_verbs.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T18:45:21.363464Z",
     "start_time": "2019-07-29T18:45:21.078314Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1524\n"
     ]
    }
   ],
   "source": [
    "## Get irregular verbs\n",
    "\n",
    "def get_tense(tense, verb):\n",
    "    table = str(word_dict_p[verb].tables_str).replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\").split(\",\")\n",
    "    if len(table) == 0 or table[0] == \"\":\n",
    "        return \"\"\n",
    "    \n",
    "    if tense in [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"]:\n",
    "        m = table.index(\"Present\")\n",
    "        return table[m + int(tense)]\n",
    "    \n",
    "    if tense == \"past\":\n",
    "        if not \"Activepastparticiple\" in table:\n",
    "            return \"\"\n",
    "        m = table.index(\"Activepastparticiple\")\n",
    "        return table[m+1]\n",
    "    \n",
    "    if tense == \"imperative\":\n",
    "        if not \"Imperative\" in table:\n",
    "            return \"\"\n",
    "        m = table.index(\"Imperative\")\n",
    "        return table[m+2]\n",
    "\n",
    "def conjugate(tense, verb):\n",
    "    \n",
    "    \n",
    "    tense_ = {}\n",
    "    if verb.endswith(\"ovati\"):\n",
    "        tense_[\"1\"] = verb[:-5] + \"ujem\"\n",
    "        tense_[\"3\"] = verb[:-5] + \"uje\"\n",
    "        tense_[\"6\"] = verb[:-5] + \"uju\"\n",
    "        tense_[\"past\"] = verb[:-5] + \"ovao\"\n",
    "        tense_[\"imperative\"] = verb[:-5] + \"uj\"\n",
    "        \n",
    "    elif verb.endswith(\"ivati\"):\n",
    "        tense_[\"1\"] = verb[:-5] + \"ujem\"\n",
    "        tense_[\"3\"] = verb[:-5] + \"uje\"\n",
    "        tense_[\"6\"] = verb[:-5] + \"uju\"\n",
    "        tense_[\"past\"] = verb[:-5] + \"ivao\"\n",
    "        tense_[\"imperative\"] = verb[:-5] + \"uj\"\n",
    "        \n",
    "    elif verb.endswith(\"jeti\"):\n",
    "        tense_[\"1\"] = verb[:-4] + \"em\"\n",
    "        tense_[\"3\"] = verb[:-4] + \"e\"\n",
    "        tense_[\"6\"] = verb[:-4] + \"u\"\n",
    "        tense_[\"past\"] = verb[:-4] + \"io\"\n",
    "        tense_[\"imperative\"] = verb[:-4] + \"i\" \n",
    "    \n",
    "    elif verb.endswith(\"ati\"):\n",
    "        tense_[\"1\"] = verb[:-3] + \"am\"\n",
    "        tense_[\"3\"] = verb[:-3] + \"a\"\n",
    "        tense_[\"6\"] = verb[:-3] + \"aju\"\n",
    "        tense_[\"past\"] = verb[:-3] + \"ao\"\n",
    "        tense_[\"imperative\"] = verb[:-3] + \"aj\"\n",
    "        \n",
    "    elif verb.endswith(\"eti\"):\n",
    "        tense_[\"1\"] = verb[:-3] + \"em\"\n",
    "        tense_[\"3\"] = verb[:-3] + \"e\"\n",
    "        tense_[\"6\"] = verb[:-3] + \"u\"\n",
    "        tense_[\"past\"] = verb[:-3] + \"o\"\n",
    "        tense_[\"imperative\"] = verb[:-3] + \"i\"\n",
    "        \n",
    "    elif verb.endswith(\"uti\"):\n",
    "        tense_[\"1\"] = verb[:-3] + \"em\"\n",
    "        tense_[\"3\"] = verb[:-3] + \"e\"\n",
    "        tense_[\"6\"] = verb[:-3] + \"u\"\n",
    "        tense_[\"past\"] = verb[:-3] + \"uo\"\n",
    "        tense_[\"imperative\"] = verb[:-3] + \"i\"\n",
    "        \n",
    "    elif verb.endswith(\"iti\"):\n",
    "        tense_[\"1\"] = verb[:-3] + \"im\"\n",
    "        tense_[\"3\"] = verb[:-3] + \"i\"\n",
    "        tense_[\"6\"] = verb[:-3] + \"e\"\n",
    "        tense_[\"past\"] = verb[:-3] + \"io\"\n",
    "        tense_[\"imperative\"] = verb[:-3] + \"i\"\n",
    "        \n",
    "        \n",
    "    if tense not in tense_:\n",
    "        return \"\"\n",
    "    return tense_[tense]\n",
    "\n",
    "  \n",
    "def get_irregulars(tense):\n",
    "    global total\n",
    "    total = 0\n",
    "    irregulars = []\n",
    "    for v in word_dict_p:\n",
    "        v = v.replace(\"2\",\"\")\n",
    "        if v not in word_dict_p or \"Verb\" not in word_dict_p[v].typ or word_dict_p[v].tables_str == \"\":\n",
    "            continue\n",
    "\n",
    "        if get_tense(tense,v) != conjugate(tense,v):\n",
    "            irregulars.append(v)\n",
    "        total += 1\n",
    "    \n",
    "    return irregulars\n",
    "\n",
    "print(len(get_irregulars(\"1\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T18:45:21.859161Z",
     "start_time": "2019-07-29T18:45:21.364461Z"
    },
    "code_folding": [
     0,
     9
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of verbs:  1605\n",
      "Total number of groups: 704\n",
      "Total number of rows:   1214\n"
     ]
    }
   ],
   "source": [
    "## Print verbs\n",
    "\n",
    "printed_verbs = []\n",
    "irregularities = get_irregulars(\"1\")\n",
    "text = \"\"\n",
    "count = 0\n",
    "d_count = 0\n",
    "g_count = 0\n",
    "\n",
    "def get_verb_definition(v):\n",
    "    if v in word_dict_p:\n",
    "        definition = word_dict_p[v].get_english().split(\" / \")[0]\n",
    "        if definition.startswith(\"perfective\") or definition.startswith(\"imperfective\"):\n",
    "            definition = word_dict_p[cousins_[v]].get_english().split(\" / \")[0]\n",
    "        if \"(\" in definition:\n",
    "            definition = definition[definition.find(\")\")+2:]\n",
    "        if len(definition) > 12:\n",
    "            definition = definition.split(\",\")[0]\n",
    "        if \" (\" in definition:\n",
    "            definition = definition.split(\" (\")[0]\n",
    "        if len(definition) > 12:    \n",
    "            definition = definition[0:10] + \"...\"\n",
    "        return \": \" + definition.replace(\"to \",\"\")\n",
    "    return \"\"\n",
    "\n",
    "def text_verb(v):\n",
    "    return_ = \"\"\n",
    "    if v not in word_dict_p:\n",
    "        return v\n",
    "    \n",
    "    if \"imperfective or perfective\" in word_dict_p[v].typ:\n",
    "        return_ = \"<i>\" + v.replace(\"2\",\"\") + \" *</i>\"\n",
    "    elif \"imperfective\" in word_dict_p[v].typ:\n",
    "        return_ = \"<i>\" + v.replace(\"2\",\"\") + \"</i>\"\n",
    "    else:\n",
    "        return_ = v.replace(\"2\",\"\")\n",
    "    \n",
    "    if v in irregularities:\n",
    "        return_ += \" ! \"\n",
    "    \n",
    "    return return_\n",
    "\n",
    "def text_of_verb_and_cousin(v):\n",
    "    text = \"\"\n",
    "    global count\n",
    "    global d_count\n",
    "    \n",
    "    v_ok = True\n",
    "    cousin_ok = True\n",
    "    if v in printed_verbs or v in uncommon_verbs or v not in word_dict_p:\n",
    "        v_ok = False\n",
    "    if v not in cousins_:\n",
    "        cousin_ok = False\n",
    "    elif cousins_[v] in printed_verbs or cousins_[v] in uncommon_verbs or cousins_[v] not in word_dict_p:\n",
    "        cousin_ok = False  \n",
    "    \n",
    "    \n",
    "    if v_ok and cousin_ok:\n",
    "        text += str(count) + \". \" + text_verb(v)\n",
    "        text += \" (\" + text_verb(cousins_[v]) + \")\"       \n",
    "        printed_verbs.append(v)\n",
    "        printed_verbs.append(cousins_[v])\n",
    "        count += 1\n",
    "        d_count += 2    \n",
    "            \n",
    "    if v_ok and not cousin_ok:\n",
    "        text += str(count) + \". \" + text_verb(v)     \n",
    "        printed_verbs.append(v)\n",
    "        \n",
    "        if v in cousins_ and cousins_[v] in word_dict_p:\n",
    "            text += \" (<s>\" + text_verb(cousins_[v]) + \"</s>)\"\n",
    "            printed_verbs.append(cousins_[v])\n",
    "        \n",
    "        count += 1\n",
    "        d_count += 1\n",
    "        \n",
    "    if not v_ok and cousin_ok:\n",
    "        text += str(count) + \". \" + \"<s>\" + text_verb(v) + \"</s>\"\n",
    "        text += \" (\" + text_verb(cousins_[v]) + \")\"       \n",
    "        printed_verbs.append(v)\n",
    "        printed_verbs.append(cousins_[v])\n",
    "        count += 1\n",
    "        d_count += 1\n",
    "    \n",
    "\n",
    "    if not v_ok and not cousin_ok:\n",
    "        return \"\"\n",
    "    \n",
    "    return text + get_verb_definition(v) + \"<br>\\n\"\n",
    "    \n",
    "    \n",
    "##############################################################\n",
    "    \n",
    "for v in main_verb_list:\n",
    "    \n",
    "    text_n = text_of_verb_and_cousin(v)\n",
    "    if v in extended_:\n",
    "        for item in extended_[v]:\n",
    "            text_n += text_of_verb_and_cousin(item)\n",
    "    \n",
    "    if text_n == \"\":\n",
    "        continue\n",
    "    text += text_n + \"<br>\\n\"\n",
    "    g_count += 1\n",
    "    \n",
    "f_out = open(\"most_frequent/Verb.html\",\"w+\",encoding=\"UTF-8\")\n",
    "f_out.write(text)\n",
    "f_out.close()\n",
    "#pyperclip.copy(text)\n",
    "print(\"Total number of verbs:  \" + str(d_count))\n",
    "print(\"Total number of groups: \" + str(g_count))\n",
    "print(\"Total number of rows:   \" + str(count-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T18:49:03.071657Z",
     "start_time": "2019-07-29T18:49:02.833493Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Missing verbs\n",
    "for word in word_dict:\n",
    "    for w in word_dict[word]:\n",
    "        if \"Verb\" not in w.typ:\n",
    "            continue\n",
    "        if w.name in printed_verbs:\n",
    "            continue\n",
    "        if freq_[w.name] < FREQ_THRESHOLD:\n",
    "            continue\n",
    "        print(w.name)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other reports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T19:10:51.937085Z",
     "start_time": "2019-07-29T19:10:51.933133Z"
    }
   },
   "outputs": [],
   "source": [
    "FREQ_THRESHOLD = 0.014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T19:10:51.991938Z",
     "start_time": "2019-07-29T19:10:51.942109Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anđeo', 'babo', 'dečko', 'dio', 'do', 'euro', 'finale', 'gospoda', 'groblje', 'kama', 'kolega', 'luda', 'oba', 'obojica', 'ocjena', 'odaja', 'orao', 'pakao', 'posao', 'prijetnja', 'prvenstvo', 'radio', 'sluga', 'smisao', 'sto', 'ubojica', 'udio', 'veo', 'vojvoda', 'vođa', 'žele', 'auto', 'papa', 'ugao', 'video', 'tata', 'moto', 'Meksiko']\n",
      "['bit', 'bol', 'bolest', 'cijev', 'crven', 'desni', 'dob', 'dobit', 'doprinos', 'financije', 'glad', 'grudi', 'hlače', 'jesen', 'kap', 'korist', 'krv', 'kćer', 'kći', 'laž', 'lisice', 'ljubav', 'mast', 'mati', 'minut', 'misao', 'momčad', 'motiv', 'moć', 'napast', 'narav', 'nauk', 'nit', 'novine', 'noć', 'obavijest', 'obitelj', 'obje', 'oblast', 'ovlast', 'pomoć', 'povijest', 'počast', 'propast', 'ravan', 'riječ', 'savjest', 'skrb', 'smrt', 'strast', 'stvar', 'svijest', 'tvar', 'urednik', 'uš', 'vaš', 'večer', 'vijest', 'vile', 'vlast', 'zamisao', 'zapovijed', 'zelen', 'zvijer', 'čast', 'os', 'ponoć', 'sol', 'četvrt', 'vrst']\n",
      "['doba', 'kola', 'leđa', 'nosila', 'pluća', 'prsa', 'usta', 'vrata']\n"
     ]
    }
   ],
   "source": [
    "## Nouns with unexpected endings\n",
    "\n",
    "fem = []\n",
    "mas = []\n",
    "neu = []\n",
    "\n",
    "for word in word_dict:\n",
    "    for w in word_dict[word]:\n",
    "        \n",
    "        if word in [\"put\"]:\n",
    "            continue\n",
    "        \n",
    "        if \"Noun\" not in w.typ:\n",
    "            continue\n",
    "         \n",
    "        if freq_[word] < FREQ_THRESHOLD:\n",
    "            continue\n",
    "        \n",
    "        if word[-1] not in [\"a\"] and \"(f)\" in w.typ and not word[-3:] == \"ost\":\n",
    "            fem.append(word)\n",
    "        if word[-1] in [\"a\",\"e\",\"o\"] and \"(m)\" in w.typ:\n",
    "            mas.append(word)\n",
    "        if word[-1] not in [\"e\",\"o\"] and \"(n)\" in w.typ:\n",
    "            neu.append(word)\n",
    "\n",
    "print(mas)\n",
    "print(fem)\n",
    "print(neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T19:10:52.047789Z",
     "start_time": "2019-07-29T19:10:51.994933Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['braća', 'cvijeće', 'djeca', 'drveće', 'dvojica', 'gospoda', 'kamenje', 'momčad', 'povrće', 'raja', 'trojica', 'voće', 'zelen']\n",
      "['desni', 'financije', 'hlače', 'kola', 'leđa', 'lisice', 'nosila', 'novine', 'pluća', 'prsa', 'usta', 'vile', 'vrata']\n"
     ]
    }
   ],
   "source": [
    "## Collectives and plural only nouns\n",
    "collectives = []\n",
    "plural_only = []\n",
    "\n",
    "for word in word_dict:\n",
    "    for w in word_dict[word]:\n",
    "        \n",
    "        if \"Noun\" not in w.typ:\n",
    "            continue\n",
    "         \n",
    "        if freq_[word] < FREQ_THRESHOLD:\n",
    "            continue\n",
    "            \n",
    "        if \"collective\" in w.get_english() or \"collectively\" in w.get_english():\n",
    "            collectives.append(word)\n",
    "        \n",
    "        if \"plural only\" in w.get_english():\n",
    "            plural_only.append(word)\n",
    "\n",
    "print(collectives)\n",
    "print(plural_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T19:10:52.119640Z",
     "start_time": "2019-07-29T19:10:52.049834Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bio', 'blizak', 'bolestan', 'cio', 'debeo', 'evropski', 'gladak', 'izvrstan', 'koristan', 'mio', 'nagao', 'nizak', 'nuždan', 'okrugao', 'podao', 'redak', 'rijedak', 'sladak', 'smio', 'svijetao', 'svjestan', 'težak', 'topao', 'uveo', 'uzak', 'veseo', 'zao', 'zreo', 'častan']\n",
      "['bijel', 'bijesan', 'blag', 'blizak', 'brz', 'dalek', 'debeo', 'dobar', 'drag', 'dubok', 'dug', 'gladak', 'glup', 'grub', 'gust', 'jak', 'kratak', 'kriv', 'lak', 'lijep', 'ljut', 'lud', 'malen', 'mek', 'mlad', 'nizak', 'redak', 'rijedak', 'siv', 'skup', 'sladak', 'smiješan', 'strog', 'suh', 'svijetao', 'tanak', 'težak', 'tih', 'tvrd', 'uzak', 'velik', 'visok', 'vrijedan', 'zao', 'čest', 'čvrst', 'širok', 'žestok', 'živ', 'žut', 'mal', 'zainteresiran']\n"
     ]
    }
   ],
   "source": [
    "## Irregular adjectives\n",
    "bad_feminines = []\n",
    "bad_comparatives = []\n",
    "\n",
    "for word in word_dict:\n",
    "    for w in word_dict[word]:\n",
    "        \n",
    "        if \"Adjective\" not in w.typ:\n",
    "            continue\n",
    "        if freq_[word] < FREQ_THRESHOLD:\n",
    "            continue\n",
    "        \n",
    "        conj = w.tables\n",
    "        for i in range(0, len(conj)):\n",
    "            conj[i] = conj[i].replace(\"a\",\"\")\n",
    "\n",
    "            \n",
    "        ##IRREGULARITIES IN FEMININE\n",
    "        if \"feminine\" in conj:\n",
    "            ind = conj.index(\"feminine\")\n",
    "\n",
    "            y = word\n",
    "            if y[-1] == \"i\":\n",
    "                y = y[:-1]\n",
    "\n",
    "            if y.replace(\"a\",\"\") != conj[ind+1]:\n",
    "                bad_feminines.append(word)\n",
    "\n",
    "        ##IRREGULARITIES IN COMPARATIVE\n",
    "        if conj.count(\"singulr\") > 2:\n",
    "\n",
    "            if word.replace(\"a\",\"\") + \"iji\" not in conj and word.replace(\"a\",\"\") + \"ji\" not in conj and conj[ind+1] + \"iji\" not in conj and conj[ind+1] + \"ji\" not in conj:\n",
    "\n",
    "                ind2 = conj.index(\"singulr\",conj.index(\"singulr\",conj.index(\"singulr\")+1)+1)\n",
    "                comparative = conj[ind2+17]\n",
    "\n",
    "                if \"og()\" in comparative:\n",
    "                    continue\n",
    "\n",
    "                bad_comparatives.append(word)\n",
    "\n",
    "print(bad_feminines)\n",
    "print(bad_comparatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h1>Nouns, adjectives and adverbs</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T19:10:52.129652Z",
     "start_time": "2019-07-29T19:10:52.121635Z"
    }
   },
   "outputs": [],
   "source": [
    "WORD_TYPE  = \"Noun\"    ## Choose Noun, Adjective or Adverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T19:10:52.139623Z",
     "start_time": "2019-07-29T19:10:52.131608Z"
    }
   },
   "outputs": [],
   "source": [
    "word_count = {}\n",
    "word_count[\"Noun\"] = 2000\n",
    "word_count[\"Adverb\"] = 500\n",
    "word_count[\"Adjective\"] = 500\n",
    "word_count[\"AdjectiveAdverb\"] = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T19:10:52.153549Z",
     "start_time": "2019-07-29T19:10:52.140622Z"
    }
   },
   "outputs": [],
   "source": [
    "left_out = {}\n",
    "left_out[\"Noun\"] = [\"bilo\",\"bio\",\"kad\",\"do\",\"bit\",\"nova\",\"bez\",\"kod\",\"pravo\",\"pod\",\"tim\",\"oko\",\"sad\",\"kada\",\"rad\",\"lak\",\"treba\",\"oka\",\"dok\",\"kraj\",\"dug\",\"mora\",\"jak\",\"igra\",\"njega\",\"radio\",\"skup\",\"crven\",\"žele\",\"težak\",\"kim\",\"nit\",\"duga\",\"baš\",\"bod\",\"bok\",\"puta\",\"minut\",\"drug\",\"kim\",\"tim\",\"ud\"]\n",
    "left_out[\"Adjective\"] = [\"bio\"]\n",
    "left_out[\"Adverb\"] = [\"bio\",\"sam\",\"ja\",\"po\",\"le\",\"di\",\"što\",\"do\",\"od\"]\n",
    "\n",
    "## combine adjectives and adverbs\n",
    "left_out[\"AdjectiveAdverb\"] = []\n",
    "left_out[\"AdjectiveAdverb\"].extend(left_out[\"Adjective\"])\n",
    "left_out[\"AdjectiveAdverb\"].extend(left_out[\"Adverb\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T19:10:52.215217Z",
     "start_time": "2019-07-29T19:10:52.154591Z"
    }
   },
   "outputs": [],
   "source": [
    "most_frequent = list(freq_.keys())\n",
    "most_frequent.sort(key = lambda x:freq_[x], reverse=True)\n",
    "\n",
    "output = open(\"most_frequent/\" + WORD_TYPE + \".html\",\"w+\",encoding=\"UTF-8\")\n",
    "\n",
    "i = 0\n",
    "for x in most_frequent:\n",
    "    word_type_ok = False\n",
    "    for item in word_dict[x]:\n",
    "        if WORD_TYPE in item.typ or item.typ in WORD_TYPE:\n",
    "            word_type_ok = True\n",
    "            break\n",
    "    \n",
    "    if x in left_out[WORD_TYPE]:\n",
    "        continue\n",
    "    \n",
    "    if x[0] == x[0].upper():\n",
    "        continue\n",
    "    \n",
    "    if not word_type_ok:\n",
    "        continue\n",
    "\n",
    "    if x in bad_feminines or x in bad_comparatives:\n",
    "        x = x + \" !\"\n",
    "    if x in collectives:\n",
    "        x = x + \" (coll)\"\n",
    "    if x in plural_only:\n",
    "        x = x + \" (pl.)\"\n",
    "    if x in fem or x in mas or x in neu:\n",
    "        x = x + word_dict[x][0].typ.replace(\"Noun \",\" \")\n",
    "    \n",
    "    output.write(x + \"\\n\")\n",
    "    i += 1\n",
    "    if i == word_count[WORD_TYPE]:\n",
    "        break\n",
    "        \n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T21:22:31.877037Z",
     "start_time": "2019-07-29T21:22:31.872503Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1864905262553457"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dave_source[\"um\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
